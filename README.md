<div style="text-align: center; max-width: 1200px; margin: 20px auto;">
<h1 style="font-weight: 600; font-size: 2rem;">
    UDiffText: A Unified Framework for High-quality Text Synthesis in Arbitrary Images via Character-aware Diffusion Models
</h1>   
<h3 style="font-weight: 450; font-size: 1rem; margin: 0rem"> 
    <a href='https://arxiv.org/pdf/******'><img src='https://img.shields.io/badge/Arxiv-******-DF826C'></a> 
    <a href='https://github.com/ZYM-PKU/UDiffText'><img src='https://img.shields.io/badge/Code-UDiffText-D0F288'></a> 
    <a href='https://huggingface.co/spaces/******'><img src='https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-UDiffText-8ADAB2'></a> 
</h3> 
<h2 style="text-align: left; font-weight: 450; font-size: 1rem; margin-top: 0.5rem; margin-bottom: 0.5rem">
    Our proposed UDiffText is capable of synthesizing accurate and harmonious text in either synthetic or real-word images, thus can be applied to tasks like scene text editing (a), arbitrary text generation (b) and accurate T2I generation (c)
</h2>
<div align=center><img src="./demo/teaser.png" alt="UDiffText" width="80%"></div> 
</div>